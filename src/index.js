#!/usr/bin/env node

// src/index.js (Version 3.0 - Enhanced AI Analysis Tool)
// Enhanced tool for AI-assisted codebase analysis and refactoring workflow

const fs = require('fs');
const path = require('path');
const program = require('commander');

// --- PROMPT GENERATION FUNCTIONS ---
function generateTaskPrompt(task, context) {
    // Generate source file context
    let sourceContext = '';
    if (task.sourceFiles?.length) {
        sourceContext = task.sourceFiles.map(file => {
            const fullPath = path.join(context.projectPath, file);
            if (fs.existsSync(fullPath)) {
                const content = fs.readFileSync(fullPath, 'utf8');
                const ext = path.extname(file).slice(1);
                return `### ${file}
\`\`\`${ext}
${content}
\`\`\``;
            }
            return `### ${file} (File not found)`;
        }).join('\n\n');
    }

    return `# ${task.title}

**Task ID:** ${task.id}
**Priority:** ${task.priority}
**Estimated Effort:** ${task.estimatedEffort}
**Status:** ${task.status}
**Tags:** ${task.tags?.join(', ') || 'none'}

## Description
${task.description}

## Project Context
- **Framework(s):** ${context.summary.frameworks.join(', ') || 'Vanilla JavaScript'}
- **Total Files:** ${context.summary.fileCount}
- **Lines of Code:** ${context.summary.linesOfCode}
- **Code Complexity:** ${context.summary.complexity}
- **Has Tests:** ${context.summary.hasTests ? 'Yes' : 'No'}

## Task Details
${task.prompt}

## Source Files to Analyze
${sourceContext || 'No specific source files provided for this task.'}

## Expected Deliverables
Please provide:
1. **Analysis** of the current state
2. **Specific recommendations** for improvement
3. **Implementation steps** or code examples
4. **Testing considerations** (if applicable)
5. **Documentation updates** needed

## Notes
- This analysis was generated on ${new Date(context.timestamp).toLocaleString()}
- Task generated by AI Refactor Tool v${context.analysisVersion}
- Copy this entire prompt to your AI assistant for best results

---
Ready to paste into Claude, ChatGPT, or any AI assistant!`;
}

function generateMasterPrompt(backlog, context) {
    const pendingTasks = backlog.tasks.filter(t => t.status === 'pending');
    const taskSummaries = pendingTasks.map(task => 
        `**[${task.id}] ${task.title}** (${task.priority})
   - ${task.description}
   - Effort: ${task.estimatedEffort}
   - Files: ${task.sourceFiles?.join(', ') || 'none'}`
    ).join('\n\n');

    return `# AI Refactoring Master Analysis

## Project Overview
**Project:** ${context.projectPath}
**Analysis Date:** ${new Date(context.timestamp).toLocaleString()}
**Framework(s):** ${context.summary.frameworks.join(', ') || 'Vanilla JavaScript'}
**Total Files:** ${context.summary.fileCount}
**Lines of Code:** ${context.summary.linesOfCode}
**Code Complexity:** ${context.summary.complexity}
**Has Tests:** ${context.summary.hasTests ? 'Yes' : 'No'}

## Generated Tasks Summary
Total tasks identified: ${backlog.tasks.length}
Pending tasks: ${pendingTasks.length}

${taskSummaries}

## How to Use Individual Task Prompts
1. Each task has been saved as a separate .txt file in the /prompts directory
2. Copy the entire content of any task file
3. Paste it into your AI assistant (Claude, ChatGPT, etc.)
4. The AI will have full context about your project and the specific task

## File Structure
\`\`\`
ai-analysis/
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îú‚îÄ‚îÄ [T-001] Add Testing Framework Setup.txt
‚îÇ   ‚îú‚îÄ‚îÄ [T-002] Refactor High Complexity Functions.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ analysis_summary.md
‚îú‚îÄ‚îÄ machine_context.json
‚îú‚îÄ‚îÄ task_backlog.json
‚îî‚îÄ‚îÄ AI_ANALYSIS_MASTER_PROMPT.txt (this file)
\`\`\`

## Next Steps
1. Review the analysis_summary.md for an overview
2. Choose a task from the prompts/ directory
3. Copy the task prompt and work with your AI assistant
4. Implement the suggested improvements
5. Mark tasks as completed in task_backlog.json

---
Generated by AI Refactor Tool v${context.analysisVersion}`;
const program = require('commander');
const babelParser = require('@babel/parser');
const crypto = require('crypto');
const chalk = require('chalk');

// --- CONSTANTS ---
const ANALYSIS_DIR = 'ai-analysis';
const ANALYSIS_SUMMARY_FILE = 'analysis_summary.md';
const MACHINE_CONTEXT_FILE = 'machine_context.json';
const TASK_BACKLOG_FILE = 'task_backlog.json';
const CODE_INVENTORY_FILE = 'code_inventory.json';
const DEPENDENCY_MAP_FILE = 'dependency_map.json';
const METRICS_FILE = 'code_metrics.json';

// Supported file extensions for analysis
const SUPPORTED_EXTENSIONS = [
    '.js', '.jsx', '.ts', '.tsx', '.vue', '.svelte', '.astro',
    '.json', '.md', '.css', '.scss', '.sass', '.less',
    '.html', '.htm', '.xml', '.yml', '.yaml', '.toml'
];

// --- UTILITY FUNCTIONS ---
function createDirectory(dir) {
    if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
        console.log(chalk.green(`‚úÖ Created directory: ${dir}`));
    }
}

// --- COMPLETE TASK COMMAND ---
function completeTask(analysisDir, taskId) {
    const backlogPath = path.join(analysisDir, TASK_BACKLOG_FILE);
    
    if (!fs.existsSync(backlogPath)) {
        console.error(chalk.red(`‚ùå Task backlog not found at "${backlogPath}".`));
        process.exit(1);
    }

    const backlog = JSON.parse(fs.readFileSync(backlogPath, 'utf8'));
    const task = backlog.tasks.find(t => t.id.toLowerCase() === taskId.toLowerCase());
    
    if (!task) {
        console.error(chalk.red(`‚ùå Task ${taskId} not found`));
        process.exit(1);
    }

    if (task.status === 'completed') {
        console.log(chalk.yellow(`‚ö†Ô∏è  Task ${taskId} is already completed`));
        return;
    }

    // Mark as completed
    task.status = 'completed';
    task.completedAt = new Date().toISOString();
    
    // Save updated backlog
    fs.writeFileSync(backlogPath, JSON.stringify(backlog, null, 2));
    
    console.log(chalk.green(`‚úÖ Task ${taskId} marked as completed: ${task.title}`));
    
    // Show remaining tasks
    const remainingTasks = backlog.tasks.filter(t => t.status === 'pending');
    if (remainingTasks.length > 0) {
        console.log(chalk.blue(`\nüìã ${remainingTasks.length} tasks remaining:`));
        remainingTasks.slice(0, 3).forEach(t => {
            console.log(chalk.gray(`   ‚Ä¢ [${t.id}] ${t.title}`));
        });
        if (remainingTasks.length > 3) {
            console.log(chalk.gray(`   ... and ${remainingTasks.length - 3} more`));
        }
    } else {
        console.log(chalk.green('\nüéâ All tasks completed! Great job!'));
    }
}

function getFileHash(filePath) {
    const content = fs.readFileSync(filePath);
    return crypto.createHash('md5').update(content).digest('hex');
}

function isTextFile(filePath) {
    const ext = path.extname(filePath).toLowerCase();
    return SUPPORTED_EXTENSIONS.includes(ext);
}

// --- ENHANCED FILE ANALYSIS ---
function analyzeJavaScriptFile(filePath) {
    try {
        const content = fs.readFileSync(filePath, 'utf8');
        
        // Try to parse with Babel
        let ast = null;
        try {
            ast = babelParser.parse(content, {
                sourceType: 'module',
                allowImportExportEverywhere: true,
                allowReturnOutsideFunction: true,
                plugins: ['jsx', 'typescript', 'decorators-legacy']
            });
        } catch (parseError) {
            // If parsing fails, continue with regex-based analysis
            console.log(chalk.yellow(`‚ö†Ô∏è  Parse warning for ${filePath}: ${parseError.message}`));
        }

        const imports = [];
        const exports = [];

        // Basic regex-based analysis (fallback)
        const importMatches = content.match(/import.*?from\s+['"`]([^'"`]+)['"`]/g) || [];
        const exportMatches = content.match(/export\s+(?:default\s+)?(?:class|function|const|let|var)\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/g) || [];
        
        importMatches.forEach(imp => {
            const match = imp.match(/from\s+['"`]([^'"`]+)['"`]/);
            if (match) imports.push(match[1]);
        });

        exportMatches.forEach(exp => {
            const match = exp.match(/(?:class|function|const|let|var)\s+([a-zA-Z_$][a-zA-Z0-9_$]*)/);
            if (match) exports.push(match[1]);
        });

        return {
            type: 'javascript',
            imports,
            exports,
            complexity: calculateComplexity(content),
            linesOfCode: content.split('\n').length,
            hasTests: content.includes('test(') || content.includes('describe(') || content.includes('it('),
            frameworks: detectFrameworks(content, filePath)
        };
    } catch (error) {
        return {
            type: 'javascript',
            error: error.message,
            imports: [],
            exports: [],
            complexity: 0,
            linesOfCode: 0
        };
    }
}

function calculateComplexity(content) {
    // Simple cyclomatic complexity estimation
    const complexityKeywords = ['if', 'else', 'for', 'while', 'case', 'catch', 'return', '&&', '||'];
    let complexity = 1;
    
    complexityKeywords.forEach(keyword => {
        const regex = new RegExp(`\\b${keyword}\\b`, 'g');
        const matches = content.match(regex);
        if (matches) complexity += matches.length;
    });
    
    return complexity;
}

function detectFrameworks(content, filePath) {
    const frameworks = [];
    
    // Check file extension first
    const ext = path.extname(filePath);
    if (ext === '.vue') {
        frameworks.push('Vue');
    } else if (ext === '.svelte') {
        frameworks.push('Svelte');
    } else if (ext === '.astro') {
        frameworks.push('Astro');
    }
    
    // Content-based detection (more specific patterns)
    const frameworkPatterns = {
        'React': {
            patterns: [
                /import\s+.*React.*from\s+['"`]react['"`]/,
                /from\s+['"`]react['"`]/,
                /useState|useEffect|useContext|useCallback/,
                /jsx|\.jsx/
            ],
            minMatches: 1
        },
        'Vue': {
            patterns: [
                /import\s+.*Vue.*from\s+['"`]vue['"`]/,
                /from\s+['"`]vue['"`]/,
                /<template>/,
                /Vue\.component/,
                /\.vue['"]/
            ],
            minMatches: 1
        },
        'Angular': {
            patterns: [
                /import.*@angular/,
                /@Component\(/,
                /@Injectable\(/,
                /@NgModule\(/
            ],
            minMatches: 1
        },
        'Svelte': {
            patterns: [
                /import.*svelte/,
                /<script\s+context=['"]module['"]>/,
                /\$\w+(?:\s*=|\s*\+=)/  // Svelte reactive statements
            ],
            minMatches: 1
        },
        'Astro': {
            patterns: [
                /^---[\s\S]*?---/m,  // Astro frontmatter
                /import.*\.astro/,
                /Astro\./,
                /---[\s\S]*---[\s\S]*<.*>/m  // Frontmatter followed by HTML
            ],
            minMatches: 1
        },
        'Express': {
            patterns: [
                /require\(['"`]express['"`]\)/,
                /from\s+['"`]express['"`]/,
                /app\.get|app\.post|app\.put|app\.delete/
            ],
            minMatches: 1
        },
        'Next.js': {
            patterns: [
                /next\//,
                /getStaticProps|getServerSideProps|getStaticPaths/,
                /from\s+['"`]next\//
            ],
            minMatches: 1
        },
        'Nuxt.js': {
            patterns: [
                /nuxt/,
                /asyncData|fetch\(/,
                /@nuxt\//
            ],
            minMatches: 1
        }
    };

    // Check content-based patterns (only if not already detected by extension)
    Object.entries(frameworkPatterns).forEach(([framework, config]) => {
        if (!frameworks.includes(framework)) {
            const matches = config.patterns.filter(pattern => pattern.test(content)).length;
            if (matches >= config.minMatches) {
                frameworks.push(framework);
            }
        }
    });

    return frameworks;
}

function analyzeConfigFile(filePath) {
    const fileName = path.basename(filePath);
    const content = fs.readFileSync(filePath, 'utf8');
    
    const configTypes = {
        'package.json': 'npm',
        'composer.json': 'composer',
        'requirements.txt': 'python',
        'Gemfile': 'ruby',
        'go.mod': 'go',
        'Cargo.toml': 'rust'
    };

    try {
        return {
            type: 'config',
            configType: configTypes[fileName] || 'unknown',
            content: fileName === 'package.json' ? JSON.parse(content) : content
        };
    } catch (error) {
        return {
            type: 'config',
            configType: configTypes[fileName] || 'unknown',
            content: content,
            error: error.message
        };
    }
}

// --- ENHANCED DIRECTORY TRAVERSAL ---
function traverseDirectory(dir, options = {}) {
    const { ignorePatterns = ['.git', 'node_modules', '.next', 'dist', 'build', 'ai-analysis'] } = options;
    const fileList = [];
    
    function traverse(currentDir) {
        try {
            const items = fs.readdirSync(currentDir);
            
            for (const item of items) {
                // More precise ignore checking
                if (ignorePatterns.some(pattern => {
                    return item === pattern || 
                           item.includes(pattern) || 
                           path.basename(currentDir) === pattern;
                })) continue;
                
                const fullPath = path.join(currentDir, item);
                
                // Skip if path contains ignored patterns
                const relativePath = path.relative(dir, fullPath);
                if (ignorePatterns.some(pattern => relativePath.includes(pattern))) continue;
                
                const stat = fs.statSync(fullPath);
                
                if (stat.isDirectory()) {
                    traverse(fullPath);
                } else if (isTextFile(fullPath) && stat.size < 1024 * 1024) { // Skip files > 1MB
                    fileList.push({
                        path: fullPath,
                        relativePath: path.relative(dir, fullPath),
                        size: stat.size,
                        modified: stat.mtime,
                        hash: getFileHash(fullPath)
                    });
                }
            }
        } catch (error) {
            console.log(chalk.yellow(`‚ö†Ô∏è  Warning: Cannot read directory ${currentDir}: ${error.message}`));
        }
    }
    
    traverse(dir);
    return fileList;
}

// --- ENHANCED ANALYSIS LOGIC ---
function runAnalysis(baseDir, options = {}) {
    console.log(chalk.blue(`üîç Starting enhanced analysis of: ${baseDir}`));
    
    if (!fs.existsSync(baseDir)) {
        console.error(chalk.red(`‚ùå Directory not found: ${baseDir}`));
        process.exit(1);
    }

    const analysisDir = path.join(baseDir, ANALYSIS_DIR);
    createDirectory(analysisDir);

    // 1. Inventory all files
    console.log(chalk.cyan('üìã Creating file inventory...'));
    const files = traverseDirectory(baseDir, options);
    
    const codeInventory = {
        totalFiles: files.length,
        totalSize: files.reduce((sum, f) => sum + f.size, 0),
        fileTypes: {},
        files: files.map(f => ({
            ...f,
            extension: path.extname(f.relativePath),
            directory: path.dirname(f.relativePath)
        }))
    };

    // Count file types
    codeInventory.files.forEach(file => {
        const ext = file.extension || 'no-extension';
        codeInventory.fileTypes[ext] = (codeInventory.fileTypes[ext] || 0) + 1;
    });

    fs.writeFileSync(
        path.join(analysisDir, CODE_INVENTORY_FILE),
        JSON.stringify(codeInventory, null, 2)
    );

    // 2. Analyze individual files
    console.log(chalk.cyan('üî¨ Analyzing individual files...'));
    const fileAnalysis = {};
    const dependencyMap = { internal: {}, external: [] };
    const metrics = {
        totalLinesOfCode: 0,
        totalComplexity: 0,
        frameworks: new Set(),
        hasTests: false,
        configFiles: []
    };

    codeInventory.files.forEach(file => {
        const fullPath = file.path;
        const ext = path.extname(fullPath);
        
        if (['.js', '.jsx', '.ts', '.tsx', '.vue', '.svelte', '.astro'].includes(ext)) {
            const analysis = analyzeJavaScriptFile(fullPath);
            fileAnalysis[file.relativePath] = analysis;
            
            metrics.totalLinesOfCode += analysis.linesOfCode || 0;
            metrics.totalComplexity += analysis.complexity || 0;
            if (analysis.hasTests) metrics.hasTests = true;
            
            analysis.frameworks?.forEach(fw => metrics.frameworks.add(fw));
            
            // Build dependency map
            analysis.imports?.forEach(imp => {
                if (imp.startsWith('.')) {
                    // Internal dependency
                    if (!dependencyMap.internal[file.relativePath]) {
                        dependencyMap.internal[file.relativePath] = [];
                    }
                    dependencyMap.internal[file.relativePath].push(imp);
                } else {
                    // External dependency
                    if (!dependencyMap.external.includes(imp)) {
                        dependencyMap.external.push(imp);
                    }
                }
            });
        } else if (['package.json', 'composer.json', 'requirements.txt'].includes(path.basename(fullPath))) {
            const configAnalysis = analyzeConfigFile(fullPath);
            metrics.configFiles.push({
                file: file.relativePath,
                type: configAnalysis.configType,
                content: configAnalysis.content
            });
        }
    });

    // Convert Set to Array for JSON serialization
    metrics.frameworks = Array.from(metrics.frameworks);

    // 3. Save analysis results
    fs.writeFileSync(
        path.join(analysisDir, DEPENDENCY_MAP_FILE),
        JSON.stringify(dependencyMap, null, 2)
    );

    fs.writeFileSync(
        path.join(analysisDir, METRICS_FILE),
        JSON.stringify(metrics, null, 2)
    );

    // 4. Generate AI-friendly summary
    const summary = generateAnalysisSummary(codeInventory, fileAnalysis, dependencyMap, metrics, baseDir);
    fs.writeFileSync(
        path.join(analysisDir, ANALYSIS_SUMMARY_FILE),
        summary
    );

    // 5. Generate machine context
    const machineContext = {
        timestamp: new Date().toISOString(),
        projectPath: baseDir,
        analysisVersion: '3.0',
        summary: {
            fileCount: codeInventory.totalFiles,
            totalSize: codeInventory.totalSize,
            linesOfCode: metrics.totalLinesOfCode,
            complexity: metrics.totalComplexity,
            frameworks: metrics.frameworks,
            hasTests: metrics.hasTests
        },
        files: fileAnalysis,
        dependencies: dependencyMap,
        metrics: metrics
    };

    fs.writeFileSync(
        path.join(analysisDir, MACHINE_CONTEXT_FILE),
        JSON.stringify(machineContext, null, 2)
    );

    // 6. Generate initial task backlog
    const taskBacklog = generateTaskBacklog(machineContext);
    fs.writeFileSync(
        path.join(analysisDir, TASK_BACKLOG_FILE),
        JSON.stringify(taskBacklog, null, 2)
    );

    // 7. Generate individual prompt files for each task
    console.log(chalk.cyan('üìù Generating AI prompt files...'));
    const promptsDir = path.join(analysisDir, 'prompts');
    createDirectory(promptsDir);
    
    taskBacklog.tasks.forEach(task => {
        const promptContent = generateTaskPrompt(task, machineContext);
        const fileName = `[${task.id}] ${task.title.replace(/[^a-zA-Z0-9\s]/g, '').replace(/\s+/g, ' ').trim()}.txt`;
        const filePath = path.join(promptsDir, fileName);
        
        fs.writeFileSync(filePath, promptContent);
        console.log(chalk.gray(`   ‚úì Created prompt: ${fileName}`));
    });

    // 8. Generate master prompt file with all tasks
    const masterPrompt = generateMasterPrompt(taskBacklog, machineContext);
    fs.writeFileSync(
        path.join(analysisDir, 'AI_ANALYSIS_MASTER_PROMPT.txt'),
        masterPrompt
    );

    console.log(chalk.green(`‚úÖ Analysis complete! Results saved in: ${analysisDir}`));
    console.log(chalk.blue(`üìä Found ${codeInventory.totalFiles} files with ${metrics.totalLinesOfCode} lines of code`));
    console.log(chalk.blue(`üîß Detected frameworks: ${metrics.frameworks.join(', ') || 'None'}`));
    console.log(chalk.yellow(`üìÅ Generated ${taskBacklog.tasks.length} AI prompt files in: ${promptsDir}`));
}

function generateAnalysisSummary(inventory, analysis, dependencies, metrics, projectPath) {
    return `# AI Refactoring Analysis Report

## Project Overview
- **Project Path**: ${projectPath}
- **Analysis Date**: ${new Date().toISOString()}
- **Total Files**: ${inventory.totalFiles}
- **Total Size**: ${(inventory.totalSize / 1024).toFixed(2)} KB
- **Lines of Code**: ${metrics.totalLinesOfCode}
- **Total Complexity**: ${metrics.totalComplexity}

## Technology Stack
${metrics.frameworks.length ? `- **Frameworks**: ${metrics.frameworks.join(', ')}` : '- **Frameworks**: None detected'}
- **Has Tests**: ${metrics.hasTests ? 'Yes' : 'No'}

## File Distribution
${Object.entries(inventory.fileTypes)
    .sort(([,a], [,b]) => b - a)
    .map(([ext, count]) => `- **${ext}**: ${count} files`)
    .join('\n')}

## Configuration Files
${metrics.configFiles.map(cf => `- **${cf.file}**: ${cf.type}`).join('\n') || 'None found'}

## External Dependencies
${dependencies.external.slice(0, 10).map(dep => `- ${dep}`).join('\n')}
${dependencies.external.length > 10 ? `... and ${dependencies.external.length - 10} more` : ''}

## Potential Refactoring Areas

### Code Quality
- Files with high complexity (>20): ${Object.entries(analysis)
    .filter(([, a]) => a.complexity && a.complexity > 20)
    .length}
- Large files (>500 LOC): ${Object.entries(analysis)
    .filter(([, a]) => a.linesOfCode && a.linesOfCode > 500)
    .length}

### Architecture
- Internal dependencies: ${Object.keys(dependencies.internal).length} files have internal imports
- External dependencies: ${dependencies.external.length} unique packages

### Recommendations
1. **Code Organization**: Review file structure and module organization
2. **Testing**: ${metrics.hasTests ? 'Expand test coverage' : 'Add comprehensive testing'}
3. **Documentation**: Add/update README and inline documentation
4. **Dependencies**: Audit and optimize external dependencies
5. **Performance**: Review large files and complex functions
6. **Standards**: Implement consistent coding standards and linting

## Next Steps
Use the generated task backlog to systematically address identified issues.
Each task is designed to be AI-assistable and includes relevant context.
`;
}

function generateTaskBacklog(context) {
    const tasks = [];
    let taskId = 1;

    // Generate tasks based on analysis
    if (!context.summary.hasTests) {
        tasks.push({
            id: `T-${String(taskId).padStart(3, '0')}`,
            title: 'Add Testing Framework Setup',
            priority: 'high',
            status: 'pending',
            description: 'Set up a testing framework and create initial test structure',
            estimatedEffort: 'medium',
            tags: ['testing', 'setup'],
            sourceFiles: ['package.json'],
            prompt: `Please help set up a comprehensive testing framework for this project. Analyze the current tech stack and recommend appropriate testing tools. Create basic test structure and configuration files.`
        });
        taskId++;
    }

    if (context.summary.complexity > 100) {
        const highComplexityFiles = Object.entries(context.files)
            .filter(([, file]) => file.complexity && file.complexity > 20)
            .map(([path]) => path);
            
        if (highComplexityFiles.length > 0) {
            tasks.push({
                id: `T-${String(taskId).padStart(3, '0')}`,
                title: 'Refactor High Complexity Functions',
                priority: 'medium',
                status: 'pending',
                description: 'Identify and refactor functions with high cyclomatic complexity',
                estimatedEffort: 'large',
                tags: ['refactoring', 'complexity'],
                sourceFiles: highComplexityFiles.slice(0, 5), // Limit to first 5
                prompt: `Please analyze these high-complexity files and suggest refactoring strategies to reduce complexity while maintaining functionality.`
            });
            taskId++;
        }
    }

    // Add documentation task if no README found
    const hasReadme = Object.keys(context.files).some(file => 
        file.toLowerCase().includes('readme')
    );
    
    if (!hasReadme) {
        tasks.push({
            id: `T-${String(taskId).padStart(3, '0')}`,
            title: 'Create Project Documentation',
            priority: 'medium',
            status: 'pending',
            description: 'Create comprehensive project documentation including README',
            estimatedEffort: 'medium',
            tags: ['documentation'],
            sourceFiles: ['package.json'],
            prompt: `Please help create comprehensive project documentation. Analyze the project structure and create a detailed README.md with installation, usage, and contribution guidelines.`
        });
        taskId++;
    }

    return {
        version: '3.0',
        generated: new Date().toISOString(),
        totalTasks: tasks.length,
        tasks
    };
}

// --- WORK COMMAND (Updated) ---
async function runWork(analysisDir, options) {
    const backlogPath = path.join(analysisDir, TASK_BACKLOG_FILE);
    const promptsDir = path.join(analysisDir, 'prompts');
    
    if (!fs.existsSync(backlogPath)) {
        console.error(chalk.red(`‚ùå Task backlog not found at "${backlogPath}". Run 'analyze' first.`));
        process.exit(1);
    }

    const backlog = JSON.parse(fs.readFileSync(backlogPath, 'utf8'));
    let taskId = options.task;

    if (!taskId) {
        const pendingTasks = backlog.tasks.filter(t => t.status === 'pending');
        if (pendingTasks.length === 0) {
            console.log(chalk.green('üéâ All tasks completed!'));
            return;
        }
        
        console.log(chalk.blue('\n--- AVAILABLE TASK PROMPTS ---'));
        
        // Show available prompt files
        if (fs.existsSync(promptsDir)) {
            const promptFiles = fs.readdirSync(promptsDir).filter(f => f.endsWith('.txt'));
            console.log(chalk.cyan(`üìÅ Found ${promptFiles.length} prompt files in: ${promptsDir}\n`));
            
            promptFiles.forEach(file => {
                const taskIdMatch = file.match(/\[([^\]]+)\]/);
                const taskId = taskIdMatch ? taskIdMatch[1] : 'Unknown';
                const task = backlog.tasks.find(t => t.id === taskId);
                const status = task ? task.status : 'unknown';
                const statusIcon = status === 'completed' ? '‚úÖ' : status === 'pending' ? '‚è≥' : '‚ùì';
                
                console.log(`${statusIcon} ${chalk.yellow(file)}`);
                if (task) {
                    console.log(`    ${chalk.gray(task.description)}`);
                    console.log(`    ${chalk.gray(`Priority: ${task.priority} | Effort: ${task.estimatedEffort}`)}\n`);
                }
            });
        }
        
        console.log(chalk.cyan('üí° Usage options:'));
        console.log('   ‚Ä¢ Copy any .txt file from the prompts/ directory');
        console.log('   ‚Ä¢ Or use: --task <ID> to output specific task to console');
        console.log('   ‚Ä¢ Or open: AI_ANALYSIS_MASTER_PROMPT.txt for overview');
        return;
    }

    // Find and output specific task
    const task = backlog.tasks.find(t => t.id.toLowerCase() === taskId.toLowerCase());
    if (!task) {
        console.error(chalk.red('‚ùå Task not found'));
        process.exit(1);
    }

    // Check if prompt file exists
    const promptFiles = fs.existsSync(promptsDir) ? fs.readdirSync(promptsDir) : [];
    const promptFile = promptFiles.find(f => f.includes(task.id));
    
    if (promptFile && fs.existsSync(path.join(promptsDir, promptFile))) {
        const promptContent = fs.readFileSync(path.join(promptsDir, promptFile), 'utf8');
        process.stdout.write(promptContent);
    } else {
        // Fallback to generating prompt on the fly
        const contextPath = path.join(analysisDir, MACHINE_CONTEXT_FILE);
        const context = fs.existsSync(contextPath) 
            ? JSON.parse(fs.readFileSync(contextPath, 'utf8'))
            : null;
            
        if (context) {
            const promptContent = generateTaskPrompt(task, context);
            process.stdout.write(promptContent);
        } else {
            console.error(chalk.red('‚ùå Could not generate prompt - missing context'));
            process.exit(1);
        }
    }
}

// --- STATUS COMMAND ---
function runStatus(analysisDir) {
    const contextPath = path.join(analysisDir, MACHINE_CONTEXT_FILE);
    const backlogPath = path.join(analysisDir, TASK_BACKLOG_FILE);
    
    if (!fs.existsSync(contextPath)) {
        console.log(chalk.red('‚ùå No analysis found. Run analyze command first.'));
        return;
    }
    
    const context = JSON.parse(fs.readFileSync(contextPath, 'utf8'));
    const backlog = fs.existsSync(backlogPath) 
        ? JSON.parse(fs.readFileSync(backlogPath, 'utf8'))
        : null;
    
    console.log(chalk.blue('üìä Project Status:'));
    console.log(`${chalk.cyan('Files:')} ${context.summary.fileCount}`);
    console.log(`${chalk.cyan('Lines of Code:')} ${context.summary.linesOfCode}`);
    console.log(`${chalk.cyan('Complexity:')} ${context.summary.complexity}`);
    console.log(`${chalk.cyan('Frameworks:')} ${context.summary.frameworks.join(', ') || 'None'}`);
    console.log(`${chalk.cyan('Has Tests:')} ${context.summary.hasTests ? 'Yes' : 'No'}`);
    console.log(`${chalk.cyan('Last Analysis:')} ${new Date(context.timestamp).toLocaleString()}`);
    
    if (backlog) {
        const pendingTasks = backlog.tasks.filter(t => t.status === 'pending');
        const completedTasks = backlog.tasks.filter(t => t.status === 'completed');
        console.log(`${chalk.cyan('Pending Tasks:')} ${pendingTasks.length}`);
        console.log(`${chalk.cyan('Completed Tasks:')} ${completedTasks.length}`);
    }
}

// --- COMMAND LINE INTERFACE ---
program
    .name('ai-refactor-tool')
    .description('Enhanced AI-assisted codebase analysis and refactoring tool')
    .version('3.0.0');

program
    .command('analyze <directory>')
    .description('Analyze a codebase and generate AI-friendly analysis')
    .option('-i, --ignore <patterns...>', 'Additional patterns to ignore', [])
    .action((directory, options) => {
        runAnalysis(directory, { 
            ignorePatterns: [...(options.ignore || []), '.git', 'node_modules', 'dist', 'build', 'ai-analysis'] 
        });
    });

program
    .command('work <analysisDir>')
    .description('Work with generated tasks')
    .option('-t, --task <taskId>', 'Generate prompt for specific task')
    .action(runWork);

program
    .command('status <analysisDir>')
    .description('Show project analysis status and metrics')
    .action(runStatus);

program
    .command('complete <analysisDir> <taskId>')
    .description('Mark a task as completed')
    .action(completeTask);

program
    .command('list <analysisDir>')
    .description('List all available prompt files')
    .action((analysisDir) => {
        const promptsDir = path.join(analysisDir, 'prompts');
        if (!fs.existsSync(promptsDir)) {
            console.log(chalk.red('‚ùå No prompts directory found. Run analyze first.'));
            return;
        }
        
        const promptFiles = fs.readdirSync(promptsDir).filter(f => f.endsWith('.txt'));
        console.log(chalk.blue(`\nüìÅ Available prompt files in: ${promptsDir}\n`));
        
        promptFiles.forEach((file, index) => {
            console.log(chalk.cyan(`${index + 1}. ${file}`));
        });
        
        console.log(chalk.gray(`\nTotal: ${promptFiles.length} files`));
        console.log(chalk.yellow('\nüí° Copy any file content to your clipboard and paste to AI assistant!'));
    });

if (require.main === module) {
    program.parse();
}

module.exports = { runAnalysis, runWork, runStatus };
